{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'spot_secrets'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-2480172b76b7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mspotipy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moauth2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSpotifyClientCredentials\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mspot_secrets\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'spot_secrets'"
     ]
    }
   ],
   "source": [
    "import spotipy\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from spotipy.oauth2 import SpotifyClientCredentials\n",
    "from spot_secrets import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Authentication\n",
    "client_credentials_manager = SpotifyClientCredentials(client_id=cid, client_secret=secret)\n",
    "sp = spotipy.Spotify(client_credentials_manager = client_credentials_manager)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(df, columns):\n",
    "    result = df.copy()\n",
    "    for feature_name in columns:\n",
    "        max_value = df[feature_name].max()\n",
    "        min_value = df[feature_name].min()\n",
    "        result[feature_name] = (df[feature_name] - min_value) / (max_value - min_value)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_features(dataframe, \n",
    "                column, \n",
    "                links = [],\n",
    "                danceability = [],\n",
    "                energy = [],\n",
    "                loudness = [],\n",
    "                speechiness = [],\n",
    "                acousticness = [],\n",
    "                instrumentalness = [],\n",
    "                liveness = [],\n",
    "                valence = [],\n",
    "                tempo = []):\n",
    "\n",
    "    for link in dataframe[column]:  \n",
    "        \n",
    "        connection = sp.audio_features(link)[0]\n",
    "        \n",
    "        links.append(link)\n",
    "        danceability.append(connection[\"danceability\"]) if connection[\"danceability\"] is not None else danceability.append(None)\n",
    "        energy.append(connection[\"energy\"]) if connection[\"energy\"] is not None else energy.append(None)\n",
    "        loudness.append(connection[\"loudness\"]) if connection[\"loudness\"] is not None else loudness.append(None)\n",
    "        speechiness.append(connection[\"speechiness\"]) if connection[\"speechiness\"] is not None else speechiness.append(None)\n",
    "        acousticness.append(connection[\"acousticness\"]) if connection[\"acousticness\"] is not None else acousticness.append(None)\n",
    "        instrumentalness.append(connection[\"instrumentalness\"]) if connection[\"instrumentalness\"] is not None else instrumentalness.append(None)\n",
    "        liveness.append(connection[\"liveness\"]) if connection[\"liveness\"] is not None else liveness.append(None)\n",
    "        valence.append(connection[\"valence\"]) if connection[\"valence\"] is not None else valence.append(None)\n",
    "        tempo.append(connection[\"tempo\"]) if connection[\"tempo\"] is not None else tempo.append(None)\n",
    "  \n",
    "    features_df = pd.DataFrame({\"song_url\": links,\n",
    "                                \"danceability\": danceability,\n",
    "                                \"energy\": energy,\n",
    "                                \"loudness\": loudness,\n",
    "                                \"speechiness\": speechiness,\n",
    "                                \"acousticness\": acousticness,\n",
    "                                \"instrumentalness\": instrumentalness,\n",
    "                                \"liveness\": liveness,\n",
    "                                \"valence\": valence,\n",
    "                                \"tempo\": tempo})\n",
    "    return features_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def call_playlist(creator, playlist_id):\n",
    "\n",
    "    playlist_features_list = [\"artist\",\n",
    "                              \"track_name\",  \n",
    "                              \"danceability\",\n",
    "                              \"energy\",\n",
    "                              \"loudness\",\n",
    "                              \"speechiness\", \n",
    "                              \"acousticness\", \n",
    "                              \"instrumentalness\",\n",
    "                              \"liveness\",\n",
    "                              \"valence\",\n",
    "                              \"tempo\"]\n",
    "    \n",
    "    playlist_df = pd.DataFrame(columns = playlist_features_list)\n",
    "\n",
    "    playlist = sp.user_playlist_tracks(creator, playlist_id)[\"items\"]\n",
    "    for track in playlist:\n",
    "\n",
    "        # Create empty dict\n",
    "        playlist_features = {}\n",
    "\n",
    "        # Get metadata\n",
    "        playlist_features[\"artist\"] = track[\"track\"][\"album\"][\"artists\"][0][\"name\"]\n",
    "        playlist_features[\"album\"] = track[\"track\"][\"album\"][\"name\"]\n",
    "        playlist_features[\"track_name\"] = track[\"track\"][\"name\"]\n",
    "        playlist_features[\"track_id\"] = track[\"track\"][\"id\"]\n",
    "        \n",
    "        # Get audio features\n",
    "        audio_features = sp.audio_features(playlist_features[\"track_id\"])[0]\n",
    "        for feature in playlist_features_list[2:]:\n",
    "            playlist_features[feature] = audio_features[feature]\n",
    "        \n",
    "        # Concat the dfs\n",
    "        track_df = pd.DataFrame(playlist_features, index = [0])\n",
    "        playlist_df = pd.concat([playlist_df, track_df], ignore_index = True)\n",
    "\n",
    "    \n",
    "    return playlist_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Some custom searching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name = \"070 Shake\"\n",
    "results = sp.search(q='artist:' + \"Rex Orange County\"+ \" track:\" + \"Loving Is Easy (feat. Benny Sings)\", type='track')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "playlist_link = \"https://open.spotify.com/playlist/37i9dQZEVXbNG2KDcFcKOF?si=1333723a6eff4b7f\"\n",
    "playlist_URI = playlist_link.split(\"/\")[-1].split(\"?\")[0]\n",
    "track_uris = [x[\"track\"][\"uri\"] for x in sp.playlist_tracks(playlist_URI)[\"items\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sp.playlist_tracks(playlist_URI)['items'][1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Downloading characteristics of songs from personal data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"/Volumes/HD/GitHub/spotify_app/spotify_data\"\n",
    "streaming_df = pd.read_csv(path + \"/streaming_history_concat.csv\", index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# counting number of plays\n",
    "plays_count = streaming_df.groupby(\"trackName\")['artistName'].count().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop duplicates\n",
    "streaming_df = streaming_df.drop_duplicates(subset=['trackName'])\n",
    "streaming_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "streaming_df = streaming_df.merge(plays_count, on=\"trackName\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sort dataframe and choose 500 most popular tracks\n",
    "streaming_df = streaming_df.sort_values(\"artistName_y\", ascending=False)\n",
    "streaming_df = streaming_df.head(int(len(streaming_df) * 0.2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "streaming_df = streaming_df.rename(columns = {\"artistName_x\": \"artistName\", \"artistName_y\": \"plays_count\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# download links of songs\n",
    "songs_links = []\n",
    "for index, song in streaming_df.iterrows():\n",
    "    results = sp.search(q='artist:' + streaming_df[\"artistName\"][index] + \" track:\" + streaming_df[\"trackName\"][index], type='track')\n",
    "    items = results['tracks']['items']\n",
    "\n",
    "    if len(items) != 0:\n",
    "        try:\n",
    "            link = items[1]['href']\n",
    "        except:\n",
    "            link = items[0]['href']\n",
    "    else:\n",
    "        link = \"\"\n",
    "    songs_links.append(link)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "streaming_df['song_url'] = songs_links\n",
    "streaming_df = streaming_df[streaming_df['song_url'] != \"\"] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get features of the songs\n",
    "features = get_features(streaming_df, \"song_url\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = features.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "streaming_df = streaming_df.merge(features, on=\"song_url\")\n",
    "streaming_df = streaming_df.drop([\"endTime\", \"song_url\", \"sec_played\"], axis=1)\n",
    "streaming_df.to_csv(\"spotify_data/personal_data_to_recommend\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "streaming_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building recommendation database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "playlist_URL = \"spotify:playlist:54A6wGeGp7yAra5hwK6xHq\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_df = call_playlist(\"spotify\", \"spotify:playlist:54A6wGeGp7yAra5hwK6xHq\").reset_index(drop=True)\n",
    "second_df = call_playlist(\"spotify\", \"spotify:playlist:3IsxzDS04BvejFJcQ0iVyW\").reset_index(drop=True)\n",
    "third_df = call_playlist(\"spotify\", \"spotify:playlist:37i9dQZEVXcEQgVh36QNFV\").reset_index(drop=True)\n",
    "fourth_df = call_playlist(\"spotify\", \"spotify:playlist:37i9dQZF1DX0YKekzl0blG\").reset_index(drop=True)\n",
    "fifth_df = call_playlist(\"spotify\", \"spotify:playlist:37i9dQZF1DX0YKekzl0blG\").reset_index(drop=True)\n",
    "sixth_df = call_playlist(\"spotify\", \"spotify:playlist:1coYrjao0tn6XY4HA6AXWV\").reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frames = [first_df, second_df, third_df, fourth_df, fifth_df, sixth_df]\n",
    "recommender_df = pd.concat(frames, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recommender_df[\"artist\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recommender_df.to_csv(\"spotify_data/playlists_data_to_recommend.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "personal_df = pd.read_csv(path + \"/personal_data_to_recommend\", index_col=0)\n",
    "recommender_df = pd.read_csv(path + \"/playlists_data_to_recommend.csv\", index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recommender_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "personal_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalizing columns with different scale\n",
    "recommender_df = normalize(recommender_df, [\"loudness\", \"tempo\"])\n",
    "personal_df = normalize(personal_df, [\"loudness\", \"tempo\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop songs from recommender which are also in the streaming history\n",
    "recommender_df = recommender_df[~recommender_df[\"track_name\"].isin(personal_df['trackName'].tolist())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare data for recommender\n",
    "personal_df = personal_df.drop([\"plays_count\"], axis=1)\n",
    "recommender_df = recommender_df.drop([\"album\", \"track_id\"], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recommender_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recommend_me(df_personal, \n",
    "                df_recommender, \n",
    "                columns_for_vector, \n",
    "                results_dict = {\"artist_personal\":[],\n",
    "                                \"track_personal\":[],\n",
    "                                \"artist_database\":[],\n",
    "                                \"track_database\":[],\n",
    "                                \"distance\":[]}\n",
    "):                                                                        \n",
    "    df_personal = df_personal.sample(int(df_personal.shape[0]/3))\n",
    "    df_recommender = df_recommender.sample(int(df_recommender.shape[0]/5))\n",
    "    \n",
    "    for i in range (0, df_personal.shape[0]):\n",
    "        \n",
    "        for j in range(0, df_recommender.shape[0]):\n",
    "            \n",
    "            distance = np.linalg.norm(df_personal[columns_for_vector].iloc[i, ].values - df_recommender[columns_for_vector].iloc[j, ].values)\n",
    "            \n",
    "            if all(distance < d for d in results_dict[\"distance\"]) and df_personal[\"artistName\"].iloc[i] not in results_dict[\"artist_personal\"] and df_recommender[\"track_name\"].iloc[j] not in results_dict[\"track_database\"]:            \n",
    "                results_dict[\"track_personal\"].append(df_personal[\"trackName\"].iloc[i])\n",
    "                results_dict[\"artist_personal\"].append(df_personal[\"artistName\"].iloc[i])\n",
    "                results_dict[\"artist_database\"].append(df_recommender[\"artist\"].iloc[j])\n",
    "                results_dict[\"track_database\"].append(df_recommender[\"track_name\"].iloc[j])\n",
    "                results_dict[\"distance\"].append(distance)\n",
    "\n",
    "            if len(results_dict[\"distance\"]) > 5:\n",
    "                lowest_value = min(results_dict[\"distance\"])\n",
    "                lowest_index = results_dict[\"distance\"].index(lowest_value)\n",
    "                \n",
    "                for key in results_dict:\n",
    "                    results_dict[key].pop(lowest_index)\n",
    "                \n",
    "    return results_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "distances = recommend_me(personal_df, recommender_df, [\"danceability\", \"energy\", \"loudness\", \"speechiness\", \"acousticness\", \"instrumentalness\", \"liveness\", \"valence\", \"tempo\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.8 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "f640a9078f8e092032cb0185e0c2b2c1ad2376cf3b94da3c4476fa7bf4b3609c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
